# Saad's Presentation Guide: DevOps, Backend & Testing

## Your Responsibility
**DevOps, Infrastructure, Backend APIs, Deployment, and Testing**

You handled AWS deployment, Docker containerization, all backend APIs (REST, gRPC, WebSocket), infrastructure setup, and comprehensive testing strategies.

---

## 1. Infrastructure Architecture

### Deployment Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AWS EC2                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Aggregator Container                       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Flower Serverâ”‚  â”‚   Ganache    â”‚  â”‚    Nginx     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  (Port 8080) â”‚  â”‚ (Port 8545)  â”‚  â”‚  (Port 80)   â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  gRPC Server â”‚  â”‚  REST API    â”‚  â”‚  WebSocket   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ (Port 50051) â”‚  â”‚ (Port 5000)  â”‚  â”‚ (Port 8765)  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Local Machine                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Hospital Container                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Flower Clientâ”‚  â”‚  Dashboard   â”‚  â”‚  TB Model    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚    (gRPC)    â”‚  â”‚  (Port 3000) â”‚  â”‚  (TensorFlow)â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Cloud Infrastructure:**
- **Provider**: AWS EC2
- **Instance**: t2.medium (2 vCPU, 4GB RAM)
- **OS**: Ubuntu 22.04 LTS
- **Region**: us-east-1

**Containerization:**
- **Docker**: 24.0.7
- **Docker Compose**: 2.23.0
- **Base Images**: Python 3.10-slim

**Networking:**
- **Ports**: 50051 (gRPC), 8080 (Flower), 8545 (Ganache), 80 (HTTP)
- **Security Groups**: Custom inbound rules
- **SSH**: Key-based authentication

---

## 2. Docker Architecture

### Aggregator Dockerfile

**File Location**: `Dockerfile.aggregator`

```dockerfile
FROM python:3.10-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    nginx \
    supervisor \
    nodejs \
    npm \
    && rm -rf /var/lib/apt/lists/*

# Install Ganache
RUN npm install -g ganache-cli

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY aggregator/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY aggregator/ ./aggregator/
COPY blockchain/ ./blockchain/
COPY shared/ ./shared/

# Copy nginx configuration
COPY nginx.conf /etc/nginx/nginx.conf

# Expose ports
EXPOSE 50051 8080 8545 80

# Start services via supervisor
CMD ["supervisord", "-c", "/etc/supervisor/supervisord.conf"]
```

**Key Decisions:**
- **Multi-service container**: Runs Flower, Ganache, Nginx in one container
- **Supervisor**: Manages multiple processes
- **Slim base image**: Reduces image size
- **No cache**: Faster builds, smaller images

### Hospital Dockerfile

**File Location**: `Dockerfile.hospital`

```dockerfile
FROM python:3.10-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy requirements
COPY hospital_node/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY hospital_node/ ./hospital_node/
COPY shared/ ./shared/

# Copy dataset
COPY data/ ./data/

# Expose dashboard port
EXPOSE 3000

# Start hospital node
CMD ["python", "hospital_node/src/main_with_dashboard.py"]
```

**Key Decisions:**
- **OpenCV dependencies**: libgl1-mesa-glx for image processing
- **Dataset included**: Baked into image for portability
- **Single process**: Simpler than aggregator

### Docker Compose

**File Location**: `docker-compose.yml`

```yaml
version: '3.8'

services:
  aggregator:
    build:
      context: .
      dockerfile: Dockerfile.aggregator
    container_name: corechain-aggregator
    ports:
      - "50051:50051"  # gRPC
      - "8080:8080"    # Flower
      - "8545:8545"    # Ganache
      - "80:80"        # HTTP
    volumes:
      - blockchain_data:/app/blockchain/ganache_data
      - aggregator_logs:/var/log
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped

  hospital:
    build:
      context: .
      dockerfile: Dockerfile.hospital
    container_name: hospital-fl-test
    ports:
      - "3000:3000"    # Dashboard
    volumes:
      - hospital_data:/data
      - hospital_history:/app/hospital_node/data
    environment:
      - HOSPITAL_ID=hospital_1
      - HOSPITAL_NAME=FL Test Hospital
      - AGGREGATOR_ADDRESS=aggregator
      - FLOWER_SERVER=aggregator:8080
      - PYTHONUNBUFFERED=1
    depends_on:
      - aggregator
    restart: unless-stopped

volumes:
  blockchain_data:
  aggregator_logs:
  hospital_data:
  hospital_history:
```

**Key Features:**
- **Named volumes**: Persist data across restarts
- **Environment variables**: Configuration without code changes
- **Depends on**: Ensures aggregator starts first
- **Restart policy**: Auto-restart on failure

---

## 3. Backend APIs

### 1. gRPC API (Hospital Registration)

**File Location**: `aggregator/src/grpc_server.py`

**Purpose**: Hospital registration and authentication

```python
import grpc
from concurrent import futures
import hospital_pb2
import hospital_pb2_grpc

class HospitalServicer(hospital_pb2_grpc.HospitalServiceServicer):
    def RegisterHospital(self, request, context):
        """Register a new hospital"""
        hospital_id = request.hospital_id
        hospital_name = request.hospital_name
        
        # Store hospital info
        hospitals[hospital_id] = {
            'name': hospital_name,
            'status': 'connected',
            'registered_at': datetime.now()
        }
        
        return hospital_pb2.RegistrationResponse(
            success=True,
            message=f"Hospital {hospital_name} registered successfully"
        )

def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    hospital_pb2_grpc.add_HospitalServiceServicer_to_server(
        HospitalServicer(), server
    )
    server.add_insecure_port('[::]:50051')
    server.start()
    server.wait_for_termination()
```

**Why gRPC?**
- **Performance**: Binary protocol, faster than JSON
- **Type Safety**: Protocol buffers enforce schema
- **Streaming**: Supports bidirectional streaming
- **Code Generation**: Auto-generate client/server code

### 2. REST API (Dashboard Data)

**File Location**: `hospital_node/src/dashboard_api.py`

**Purpose**: Dashboard data and training control

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

@app.get("/api/status")
async def get_status():
    """Get hospital status"""
    return {
        "hospital_id": "hospital_1",
        "hospital_name": "FL Test Hospital",
        "aggregator_connected": True,
        "is_training": True,
        "current_round": 2,
        "total_rounds": 10,
        "token_balance": 150
    }

@app.get("/api/rounds")
async def get_rounds():
    """Get training history"""
    with open('/data/history.json') as f:
        history = json.load(f)
    return history

@app.post("/api/training/start")
async def start_training():
    """Start FL training"""
    # Trigger training in background
    threading.Thread(target=run_training).start()
    return {"status": "training_started"}
```

**Why FastAPI?**
- **Fast**: High performance (async support)
- **Auto Documentation**: Swagger UI included
- **Type Validation**: Pydantic models
- **Modern**: Python 3.10+ features

### 3. WebSocket API (Real-time Updates)

**File Location**: `aggregator/src/websocket_server.py`

**Purpose**: Real-time training updates

```python
import asyncio
import websockets
import json

connected_clients = set()

async def handler(websocket, path):
    """Handle WebSocket connections"""
    connected_clients.add(websocket)
    try:
        async for message in websocket:
            # Echo or process message
            await websocket.send(message)
    finally:
        connected_clients.remove(websocket)

async def broadcast_update(data):
    """Broadcast update to all connected clients"""
    if connected_clients:
        message = json.dumps(data)
        await asyncio.gather(
            *[client.send(message) for client in connected_clients]
        )

async def main():
    async with websockets.serve(handler, "0.0.0.0", 8765):
        await asyncio.Future()  # Run forever

if __name__ == "__main__":
    asyncio.run(main())
```

**Why WebSockets?**
- **Real-time**: Instant updates without polling
- **Bidirectional**: Two-way communication
- **Efficient**: Persistent connection
- **Standard**: Widely supported

---

## 4. AWS Deployment

### Deployment Script

**File Location**: `deploy-aws.sh`

```bash
#!/bin/bash

# Configuration
EC2_IP="54.173.119.88"
KEY_FILE="corechain-key.pem"
SSH_USER="ubuntu"

echo "ğŸš€ Deploying CoreChain to AWS..."

# 1. Copy files to EC2
echo "ğŸ“¦ Copying files..."
scp -i $KEY_FILE -r \
    aggregator/ \
    blockchain/ \
    shared/ \
    Dockerfile.aggregator \
    docker-compose.yml \
    $SSH_USER@$EC2_IP:/home/ubuntu/corechain/

# 2. SSH and build
echo "ğŸ”¨ Building Docker images..."
ssh -i $KEY_FILE $SSH_USER@$EC2_IP << 'EOF'
    cd /home/ubuntu/corechain
    
    # Stop existing containers
    docker-compose down
    
    # Build new images
    docker-compose build --no-cache
    
    # Start containers
    docker-compose up -d
    
    # Show logs
    docker-compose logs -f
EOF

echo "âœ… Deployment complete!"
```

**Deployment Steps:**
1. **File Transfer**: SCP to EC2
2. **Stop Containers**: Clean shutdown
3. **Build Images**: Fresh build
4. **Start Services**: Launch containers
5. **Monitor Logs**: Verify startup

### Security Group Configuration

**Inbound Rules:**
| Port | Protocol | Source | Purpose |
|------|----------|--------|---------|
| 22 | TCP | Your IP | SSH access |
| 80 | TCP | 0.0.0.0/0 | HTTP (dashboard) |
| 8080 | TCP | 0.0.0.0/0 | Flower server |
| 8545 | TCP | 0.0.0.0/0 | Ganache RPC |
| 50051 | TCP | 0.0.0.0/0 | gRPC |

**Outbound Rules:**
- All traffic allowed (default)

---

## 5. Testing Strategy

### 1. Unit Tests

**File Location**: `tests/test_fl_trainer.py`

```python
import unittest
from hospital_node.src.fl_trainer import FlowerClient

class TestFlowerClient(unittest.TestCase):
    def setUp(self):
        """Set up test fixtures"""
        self.model = create_test_model()
        self.x_train = np.random.rand(100, 224, 224, 3)
        self.y_train = np.random.randint(0, 2, 100)
        self.client = FlowerClient(
            self.model,
            self.x_train,
            self.y_train,
            None,
            None
        )
    
    def test_get_parameters(self):
        """Test parameter retrieval"""
        params = self.client.get_parameters({})
        self.assertEqual(len(params), 56)  # 56 weight arrays
    
    def test_fit(self):
        """Test local training"""
        initial_params = self.client.get_parameters({})
        updated_params, num_examples, metrics = self.client.fit(
            initial_params, {}
        )
        
        self.assertEqual(num_examples, 100)
        self.assertIn('accuracy', metrics)
        self.assertIn('loss', metrics)
```

### 2. Integration Tests

**File Location**: `test_hospital.py`

```python
import requests
import time

def test_hospital_dashboard():
    """Test hospital dashboard API"""
    response = requests.get('http://localhost:3000/api/status')
    assert response.status_code == 200
    
    data = response.json()
    assert 'hospital_id' in data
    assert 'aggregator_connected' in data

def test_flower_connection():
    """Test Flower server connection"""
    # Start hospital client
    subprocess.Popen(['python', 'hospital_node/src/main.py'])
    
    # Wait for connection
    time.sleep(10)
    
    # Check logs for connection success
    logs = subprocess.check_output(['docker', 'logs', 'hospital-fl-test'])
    assert b'Connected to aggregator' in logs

def test_end_to_end_training():
    """Test complete FL training round"""
    # Start aggregator
    subprocess.Popen(['docker-compose', 'up', 'aggregator'])
    time.sleep(30)
    
    # Start hospital
    subprocess.Popen(['docker-compose', 'up', 'hospital'])
    time.sleep(10)
    
    # Wait for round completion
    time.sleep(300)  # 5 minutes
    
    # Check training history
    response = requests.get('http://localhost:3000/api/rounds')
    rounds = response.json()
    
    assert len(rounds) > 0
    assert rounds[0]['status'] == 'completed'
```

### 3. Load Testing

**File Location**: `tests/load_test.py`

```python
import asyncio
import aiohttp

async def simulate_hospital(session, hospital_id):
    """Simulate hospital API calls"""
    for _ in range(100):
        async with session.get(f'http://localhost:3000/api/status') as resp:
            assert resp.status == 200
        await asyncio.sleep(0.1)

async def load_test():
    """Simulate 10 hospitals making concurrent requests"""
    async with aiohttp.ClientSession() as session:
        tasks = [
            simulate_hospital(session, i)
            for i in range(10)
        ]
        await asyncio.gather(*tasks)

if __name__ == '__main__':
    asyncio.run(load_test())
```

---

## 6. Monitoring & Logging

### Logging Configuration

**File Location**: `hospital_node/src/main.py`

```python
from loguru import logger

# Configure logger
logger.add(
    "/var/log/hospital.log",
    rotation="500 MB",
    retention="10 days",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
)

# Usage
logger.info("Hospital starting...")
logger.success("Connected to aggregator")
logger.error("Training failed: {error}", error=str(e))
```

### Log Locations

| Component | Log File | Access Method |
|-----------|----------|---------------|
| Flower Server | `/var/log/flower.err.log` | `docker exec corechain-aggregator tail -f /var/log/flower.err.log` |
| Hospital Node | Docker logs | `docker logs -f hospital-fl-test` |
| Nginx | `/var/log/nginx/access.log` | `docker exec corechain-aggregator tail -f /var/log/nginx/access.log` |
| Ganache | Docker logs | `docker exec corechain-aggregator tail -f /var/log/ganache.log` |

---

## 7. CI/CD Considerations

### GitHub Actions Workflow (Future)

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: |
          python -m pytest tests/
  
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Build Docker images
        run: |
          docker-compose build
  
  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to AWS
        run: |
          ./deploy-aws.sh
```

---

## 8. Key Files You Should Know

### DevOps Files
| File | Purpose | Your Contribution |
|------|---------|-------------------|
| `Dockerfile.aggregator` | Aggregator container | Complete Dockerfile |
| `Dockerfile.hospital` | Hospital container | Complete Dockerfile |
| `docker-compose.yml` | Multi-container setup | Complete orchestration |
| `deploy-aws.sh` | Deployment script | Automated deployment |
| `nginx.conf` | Web server config | Reverse proxy setup |

### Backend API Files
| File | Purpose | Your Contribution |
|------|---------|-------------------|
| `aggregator/src/grpc_server.py` | gRPC API | Complete implementation |
| `aggregator/src/rest_api.py` | REST API | Complete implementation |
| `aggregator/src/websocket_server.py` | WebSocket API | Complete implementation |
| `hospital_node/src/dashboard_api.py` | Dashboard API | Complete implementation |

### Testing Files
| File | Purpose | Your Contribution |
|------|---------|-------------------|
| `test_hospital.py` | Integration tests | Complete test suite |
| `tests/test_fl_trainer.py` | Unit tests | Complete test suite |
| `tests/load_test.py` | Load tests | Performance testing |

---

## 9. Presentation Talking Points

### Opening (30 seconds)
"I handled all DevOps, infrastructure, and backend development. This includes AWS deployment, Docker containerization, three different API protocols, and comprehensive testing to ensure system reliability."

### Technical Deep Dive (2 minutes)

**Infrastructure:**
"The system runs on AWS EC2 with Docker containers. The aggregator container runs multiple services (Flower, Ganache, Nginx) managed by Supervisor. I configured security groups to expose necessary ports while maintaining security."

**Backend APIs:**
"I implemented three API protocols:
1. **gRPC** for hospital registration (high performance, type-safe)
2. **REST** for dashboard data (simple, widely supported)
3. **WebSockets** for real-time updates (bidirectional, efficient)"

**Deployment:**
"I created an automated deployment script that transfers files to EC2, builds Docker images, and starts services. The entire deployment takes about 5 minutes."

**Testing:**
"I implemented unit tests for FL components, integration tests for end-to-end workflows, and load tests to verify the system can handle multiple concurrent hospitals."

### Demo Points
1. Show Docker containers running on AWS
2. Demonstrate deployment script execution
3. Show API endpoints (Swagger UI for REST)
4. Display monitoring logs
5. Run integration test

### Closing (30 seconds)
"The infrastructure is production-ready, fully containerized, and can scale to support multiple hospitals. The automated deployment and comprehensive testing ensure reliability and maintainability."

---

## 10. Common Questions & Answers

**Q: Why Docker instead of running directly on EC2?**
A: "Docker provides isolation, portability, and consistency. We can develop locally and deploy to AWS with identical environments. It also makes scaling easierâ€”we can add more containers as needed."

**Q: Why multiple API protocols?**
A: "Each protocol serves a specific purpose: gRPC for performance-critical hospital registration, REST for simple dashboard queries, and WebSockets for real-time updates. Using the right tool for each job optimizes the system."

**Q: How do you handle container failures?**
A: "Docker Compose is configured with `restart: unless-stopped`, so containers automatically restart on failure. We also have health checks and monitoring to detect issues quickly."

**Q: What about security?**
A: "We use AWS security groups to restrict access, SSH key-based authentication, and plan to add HTTPS/TLS for production. Currently, it's a development environment with controlled access."

**Q: Can the system scale to 100 hospitals?**
A: "Yes! The architecture is designed for scalability. We can add more EC2 instances, use a load balancer, and deploy hospitals in different regions. Flower supports thousands of clients."

---

## 11. Performance Metrics

### System Performance
- **Container Startup**: ~30 seconds
- **API Response Time**: < 100ms (REST), < 50ms (gRPC)
- **Deployment Time**: ~5 minutes (full deployment)
- **Image Size**: Aggregator (2.1 GB), Hospital (1.8 GB)

### Resource Usage
- **CPU**: 20-30% during training, < 5% idle
- **Memory**: 2.5 GB (aggregator), 1.8 GB (hospital)
- **Network**: ~60 MB/round (parameter transfer)
- **Disk**: 10 GB (with dataset and blockchain data)

---

## 12. Troubleshooting Guide

### Common Issues

**Issue**: Container won't start
```bash
# Check logs
docker logs corechain-aggregator

# Check port conflicts
sudo lsof -i :8080

# Restart container
docker-compose restart aggregator
```

**Issue**: Can't connect to AWS
```bash
# Test SSH
ssh -i corechain-key.pem ubuntu@54.173.119.88

# Check security group
aws ec2 describe-security-groups --group-ids sg-xxxxx
```

**Issue**: API not responding
```bash
# Check if service is running
docker exec corechain-aggregator ps aux | grep python

# Test endpoint
curl http://localhost:3000/api/status
```

---

## 13. Future Enhancements (If Asked)

1. **Kubernetes**: Migrate from Docker Compose to K8s for better orchestration
2. **CI/CD Pipeline**: GitHub Actions for automated testing and deployment
3. **Monitoring**: Prometheus + Grafana for metrics visualization
4. **HTTPS/TLS**: SSL certificates for secure communication
5. **Multi-Region**: Deploy aggregators in multiple AWS regions
6. **Auto-Scaling**: Scale hospital containers based on load

---

## Summary Checklist

Before presentation, make sure you can explain:
- âœ… Infrastructure architecture (AWS EC2 + Docker)
- âœ… Docker setup (multi-service containers, volumes)
- âœ… Three API protocols (gRPC, REST, WebSocket) and why
- âœ… Deployment process (automated script)
- âœ… Security configuration (security groups, SSH keys)
- âœ… Testing strategy (unit, integration, load tests)
- âœ… Monitoring and logging setup
- âœ… Performance metrics and resource usage
- âœ… Troubleshooting common issues
- âœ… File locations for all DevOps/backend code
- âœ… Scalability considerations

**You've got this! ğŸš€**
